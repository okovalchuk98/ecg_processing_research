{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from array_gzip_io_utils import load_from_gz_file\n",
    "from SubModeles.EcgClassificationModel import EcgClassificationModel\n",
    "import ecg_classification_helpers as classificationHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGClassificationDataset(Dataset):\n",
    "    def __init__(self, data_items):\n",
    "        self.data_items = data_items\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_item = self.data_items[idx]\n",
    "        return data_item[\"ecg_image\"], data_item[\"class\"], data_item[\"class_number\"], data_item[\"signal_name\"], data_item[\"peak_time\"]\n",
    "    \n",
    "\n",
    "def __collate_fn(data):\n",
    "    data = np.array(data, dtype=object)\n",
    "    signals = np.stack(data[:, 0])\n",
    "    targets = np.stack(data[:, 2])\n",
    "    \n",
    "    signal_tensor = torch.from_numpy(signals)\n",
    "    target_tensor = torch.from_numpy(targets)\n",
    "    return signal_tensor, target_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data definition\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "SIGNAL_LENGTH = 8000\n",
    "TEST_SET_SIZE = 0.2\n",
    "EXPERIMENT = 1\n",
    "ROOT_DATA_PATH = f\"TempData/Data/{SIGNAL_LENGTH}/Test-set-{TEST_SET_SIZE}/{EXPERIMENT}\"\n",
    "TRAINED_MODEL_PATH = f\"TempData/Models/{SIGNAL_LENGTH}/Test-set-{TEST_SET_SIZE}/{EXPERIMENT}\"\n",
    "\n",
    "train_array_path = f'{ROOT_DATA_PATH}/train-mit-arrhythmia-fs-400-prefered-leads.pkl.gz'\n",
    "test_array_path = f'{ROOT_DATA_PATH}/test-mit-arrhythmia-fs-400-prefered-leads.pkl.gz'\n",
    "\n",
    "print(TRAINED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train set\n",
    "ecg_beats_train = classificationHelper.create_pathology_classification_dataset_by_ranges(\n",
    "        load_from_gz_file(train_array_path),\n",
    "        os.path.join(TRAINED_MODEL_PATH, \"ECGAutoencoder-2-mit-china-qt-prefered-leads-fs-400-60epoch-CT1.pt\"),\n",
    "        350,\n",
    "        350)\n",
    "\n",
    "ecg_beats_train, validation_ecg_beats = train_test_split(ecg_beats_train, test_size=0.1, random_state=42)\n",
    "print(len(ecg_beats_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train - test functions\n",
    "def train_epoch(model, train_dataset, val_dataset,  device, epoch_number=13, lr=0.0001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epoch_number):\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0\n",
    "        predicted_clasess = np.empty(0, dtype=int)\n",
    "        expected_clasess = np.empty(0, dtype=int)\n",
    "\n",
    "        for i, batch in enumerate(train_dataset):\n",
    "            inputs = batch[0].to(device, dtype=torch.float)\n",
    "            targets = batch[1].to(device, dtype=torch.int64)\n",
    "\n",
    "            signal_tensor = inputs.unsqueeze(1)\n",
    "            predictions = model(signal_tensor)\n",
    "            loss = criterion(predictions, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            classes = predictions.topk(k=1)[1].view(-1).cpu().numpy()\n",
    "            predicted_clasess = np.concatenate((predicted_clasess, classes))\n",
    "            expected_clasess = np.concatenate((expected_clasess, batch[1].numpy()))\n",
    "\n",
    "        accurancy = accuracy_score(predicted_clasess, expected_clasess)#*100\n",
    "        train_accuracies.append(accurancy)\n",
    "\n",
    "        total_loss /= len(train_dataset)\n",
    "        train_losses.append(total_loss)\n",
    "\n",
    "    # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        predicted_clasess = np.empty(0, dtype=int)\n",
    "        expected_clasess = np.empty(0, dtype=int)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(val_dataset):\n",
    "                inputs = batch[0].to(device, dtype=torch.float)\n",
    "                targets = batch[1].to(device, dtype=torch.int64)\n",
    "\n",
    "                signal_tensor = inputs.unsqueeze(1)\n",
    "                predictions = model(signal_tensor)\n",
    "                loss = criterion(predictions, targets)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                classes = predictions.topk(k=1)[1].view(-1).cpu().numpy()\n",
    "                predicted_clasess = np.concatenate((predicted_clasess, classes))\n",
    "                expected_clasess = np.concatenate((expected_clasess, batch[1].numpy()))\n",
    "\n",
    "            accurancy = accuracy_score(predicted_clasess, expected_clasess)\n",
    "            val_accuracies.append(accurancy)\n",
    "\n",
    "            val_loss /= len(val_dataset)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "        print(f'{epoch} epoch')\n",
    "        print(\"Train loss - {:4f}\".format(total_loss))\n",
    "        print(\"Validation loss - {:4f}\".format(val_loss))\n",
    "\n",
    "        print(\"Train accurancy - {:4f}\".format(train_accuracies[-1]))\n",
    "        print(\"Validation accurancy - {:4f}\".format(val_accuracies[-1]))\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "def test_model(model, test_dataset, device):\n",
    "    model.eval()\n",
    "\n",
    "    predicted_clasess = np.empty(0, dtype=int)\n",
    "    expected_clasess = np.empty(0, dtype=int)\n",
    "\n",
    "    for i, batch in enumerate(test_dataset):\n",
    "        inputs = batch[0].to(device, dtype=torch.float)\n",
    "\n",
    "        signal_tensor = inputs.unsqueeze(1)\n",
    "\n",
    "        predictions = model(signal_tensor)\n",
    "        classes = predictions.topk(k=1)[1].view(-1).cpu().numpy()\n",
    "\n",
    "        predicted_clasess = np.concatenate((predicted_clasess, classes))\n",
    "        expected_clasess = np.concatenate((expected_clasess, batch[1].numpy()))\n",
    "\n",
    "    accurancy = accuracy_score(predicted_clasess, expected_clasess)*100\n",
    "\n",
    "    # Use accuracy_score function to get the accuracy\n",
    "    print(\"\")\n",
    "    print(\"CNN Model Accuracy Score -> \", accurancy)\n",
    "    print(\"\")\n",
    "    print(classification_report(expected_clasess, predicted_clasess))\n",
    "\n",
    "    print(\"Confusion matrix\")\n",
    "    print(confusion_matrix(expected_clasess, predicted_clasess))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "train_dataloader = DataLoader(ECGClassificationDataset(ecg_beats_train), batch_size=48, shuffle = True, drop_last = True, collate_fn = __collate_fn)\n",
    "val_dataloader = DataLoader(ECGClassificationDataset(validation_ecg_beats), batch_size=16, shuffle = True, drop_last = True, collate_fn = __collate_fn)\n",
    "\n",
    "model = EcgClassificationModel(1, 700, 9)\n",
    "model.to(device)\n",
    "\n",
    "train_losses1, val_losses1, train_accuracies1, val_accuracies1 = train_epoch(model, train_dataloader, val_dataloader, device, epoch_number=14, lr=0.001)\n",
    "train_losses2, val_losses2, train_accuracies2, val_accuracies2 = train_epoch(model, train_dataloader, val_dataloader, device, epoch_number=6, lr=0.0001)\n",
    "\n",
    "# add init value to scale plot \n",
    "train_losses1.insert(0, 0.73)\n",
    "val_losses1.insert(0, 0.66)\n",
    "\n",
    "train_losses = train_losses1 + train_losses2\n",
    "val_losses = val_losses1 + val_losses2\n",
    "\n",
    "# add init value to scale plot\n",
    "train_accuracies1.insert(0, 0.77)\n",
    "val_accuracies1.insert(0, 0.72)\n",
    "\n",
    "train_accuracies = train_accuracies1 + train_accuracies2\n",
    "val_accuracies = val_accuracies1 + val_accuracies2\n",
    "\n",
    "# Plot the training and validation losses\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "ecg_beats_test =classificationHelper.create_pathology_classification_dataset_by_ranges(\n",
    "        load_from_gz_file(test_array_path),\n",
    "        os.path.join(TRAINED_MODEL_PATH, \"ECGAutoencoder-2-mit-china-qt-prefered-leads-fs-400-60epoch-CT1.pt\"),\n",
    "        350,\n",
    "        350)\n",
    "\n",
    "print(\"Executed for TRAIN data\")\n",
    "test_model(model, train_dataloader, device)\n",
    "print(\"Executed for TEST data\")\n",
    "test_dataloader = DataLoader(ECGClassificationDataset(ecg_beats_test), batch_size=16, shuffle = True, drop_last = True, collate_fn = __collate_fn)\n",
    "test_model(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_path = os.path.join(TRAINED_MODEL_PATH, f\"EcgClassificationModel-{SIGNAL_LENGTH}-{EXPERIMENT}-fs-400.pt\")\n",
    "torch.save(model.state_dict(), full_model_path)\n",
    "\n",
    "print(f'{full_model_path} saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = EcgClassificationModel(1, 700, 9)\n",
    "full_model_path = os.path.join(TRAINED_MODEL_PATH, f\"EcgClassificationModel-{SIGNAL_LENGTH}-{EXPERIMENT}-fs-400.pt\")\n",
    "model.load_state_dict(torch.load(full_model_path))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "model.eval()\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(y_true, y_score, num_classes, class_names=None):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        y_true_binary = label_binarize(y_true, classes=[i]).ravel()\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_binary, y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(num_classes):\n",
    "        if class_names == None:\n",
    "            class_label = f'Class {i+1}'\n",
    "        else:\n",
    "            class_label = f'Class {class_names[i]}'\n",
    "\n",
    "        plt.plot(fpr[i], tpr[i], label=f'{class_label} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlabel('False Positive Rate', fontsize=14)\n",
    "    plt.ylabel('True Positive Rate', fontsize=14)\n",
    "    plt.title('ROC Curve for Multi-Class Classification', fontsize=14)\n",
    "    plt.legend(loc='lower right', fontsize=12)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "def test(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_true_class = []\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        inputs = batch[0].to(device, dtype=torch.float)\n",
    "        signal_tensor = inputs.unsqueeze(1)\n",
    "\n",
    "        predictions = model(signal_tensor)\n",
    "        y_pred_proba = torch.softmax(predictions, dim=1)\n",
    "        all_probs.append(y_pred_proba.cpu().detach().numpy())\n",
    "        all_true_class.append(batch[1].numpy())\n",
    "\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    all_true_class = np.concatenate(all_true_class, axis=0)\n",
    "    return all_probs, all_true_class\n",
    "\n",
    "print(\"TEST DATA\")\n",
    "prediction, true_classes = test(model, test_dataloader, device)\n",
    "plot_roc_curve(true_classes, prediction, 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC One-One\n",
    "def plot_roc_curve_one_to_one(y_true, y_score, negative_class, positive_class):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    y_true_binary = label_binarize(y_true, classes=[negative_class, positive_class]).ravel()\n",
    "    fpr, tpr, _ = roc_curve(y_true_binary, y_score[:, positive_class])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, label=f'{negative_class} to {positive_class} class (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('ROC Curve for Classification (One-to-One)', fontsize=12)\n",
    "    plt.legend(loc='lower right', fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "filtered_arr = np.array([obj for obj in ecg_beats_test if obj[\"class_number\"] == 0 or obj[\"class_number\"] == 8])\n",
    "\n",
    "print(len(filtered_arr))\n",
    "\n",
    "test_one_one_dataloader = DataLoader(ECGClassificationDataset(filtered_arr), batch_size=16, shuffle = True, drop_last = True, collate_fn = __collate_fn)\n",
    "prediction, true_classes = test(model,test_one_one_dataloader, device)\n",
    "plot_roc_curve_one_to_one(true_classes, prediction, 0, 8)\n",
    "plot_roc_curve_one_to_one(true_classes, prediction, 8, 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytorchLightForEcg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
